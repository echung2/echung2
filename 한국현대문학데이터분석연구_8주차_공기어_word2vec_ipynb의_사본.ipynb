{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/echung2/echung2/blob/master/%ED%95%9C%EA%B5%AD%ED%98%84%EB%8C%80%EB%AC%B8%ED%95%99%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EC%97%B0%EA%B5%AC_8%EC%A3%BC%EC%B0%A8_%EA%B3%B5%EA%B8%B0%EC%96%B4_word2vec_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwdE2ywZO5T0"
      },
      "source": [
        "## 공기어 분석"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-9bCkq-R0C2"
      },
      "source": [
        "### 0. 자료 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5DP-76mU8oa"
      },
      "source": [
        "# 나눔고딕\n",
        "!apt-get update -qq\n",
        "!apt-get install fonts-nanum* -qq\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf\n",
        "\n",
        "# 패키지 설치\n",
        "!pip install -U gensim kiwipiepy flashtext scikit-learn delayed -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFPVmFO-SEcn"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from kiwipiepy import Kiwi, Option\n",
        "kiwi = Kiwi()\n",
        "kiwi.prepare()\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "font_path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "\n",
        "import itertools\n",
        "from collections import Counter\n",
        "\n",
        "import regex #확장된 정규표현식. 일반 정규표현식은 import re\n",
        "\n",
        "from flashtext import KeywordProcessor\n",
        "kp = KeywordProcessor()\n",
        "\n",
        "from gensim.test.utils import common_texts\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "wordcloud = WordCloud()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0iWh9GlO-OY"
      },
      "source": [
        "# 이인직 소설 자료 다운로드\n",
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1AY763FcPXN_iBo_sVMXHugQ8UHFvb_nN' -O lee.xlsx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VlLn1HNQL9U"
      },
      "source": [
        "df = pd.read_excel('lee.xlsx')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly5eJsDOTt9_"
      },
      "source": [
        "### 1. 형태소 분석 및 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kyryal6aVoQX"
      },
      "source": [
        "##### 사용자 사전 등록"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpKqjU3YW1Hq"
      },
      "source": [
        "kiwi.analyze('혈의누의 옥련은 운다. 훌쩍이다')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nm67pepBWd0M"
      },
      "source": [
        "# 사용자 사전 활용\n",
        "# kiwi.load_user_dictionary(\"dic.txt\")\n",
        "# kiwi.prepare()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsdbpXhwYg1z"
      },
      "source": [
        "kiwi.analyze('옥련은 혈의누의 주인공이다.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvinXevpXZ2r"
      },
      "source": [
        "##### 형태소 분석\n",
        "품사 참고 : https://bab2min.github.io/kiwipiepy/v0.9.2/kr/#_7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOwnDTGrXbeg"
      },
      "source": [
        "# 몇가지 품사 제외한 모든 품사 추출\n",
        "def tokenize(sent):\n",
        "    res, score = kiwi.analyze(sent)[0] # 첫번째 결과를 사용\n",
        "    return [word + ('다' if tag.startswith('V') else '') # 동사/형용사에는 '다'를 붙여줌\n",
        "    # return [word + ('다' if tag.startswith('V') else '')+ '/'+ tag # 동사/형용사에는 '다'를 붙여줌 + / 품사\n",
        "            for word, tag, _, _ in res\n",
        "            if not tag.startswith('E') and not tag.startswith('J') and not tag.startswith('S')] # 조사, 어미, 특수기호 및 stopwords에 포함된 단어는 제거"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkRpQBt9uawh"
      },
      "source": [
        "# 몇가지 품사 제외한 모든 품사 추출 + 품사 태그 포함\n",
        "def tokenize_tag(sent):\n",
        "    res, score = kiwi.analyze(sent)[0] # 첫번째 결과를 사용\n",
        "    return [word + ('다' if tag.startswith('V') else '')+ '/'+ tag # 동사/형용사에는 '다'를 붙여줌 + / 품사\n",
        "            for word, tag, _, _ in res\n",
        "            if not tag.startswith('E') and not tag.startswith('J') and not tag.startswith('S')] # 조사, 어미, 특수기호 및 stopwords에 포함된 단어는 제거"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6NIuzeWs_Yz"
      },
      "source": [
        "# 특정 품사만 추출\n",
        "def tokenize_part(sent):\n",
        "    res, score = kiwi.analyze(sent)[0] # 첫번째 결과를 사용\n",
        "    return [word\n",
        "            for word, tag, _, _ in res\n",
        "            if tag.startswith('NN')] # 'NN'으로 시작하는 품사만 추출 = 명사만 추출"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hx20NWkY20W"
      },
      "source": [
        "df['paragraph'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbyeLTunXxO2"
      },
      "source": [
        "tokenize_tag(df['paragraph'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdOGyWHBZfRz"
      },
      "source": [
        "df['tokens'] = df['paragraph'].progress_map(lambda x:tokenize_tag(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXSODw4mZoRo"
      },
      "source": [
        "df['tokens']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pMTOWpBZC80"
      },
      "source": [
        "##### 불용어 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5nnTorSjXWP"
      },
      "source": [
        "# 상위 n개 단어 확인\n",
        "token_list = list(itertools.chain(*df['tokens'].tolist()))\n",
        "cnt = Counter(token_list)\n",
        "cnt.most_common(30) # 상위 20개"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ytKtIMzZEhl"
      },
      "source": [
        " # 불용어 리스트\n",
        "stopwords = set(['이다/VCP','하다/VV','하다/VX','위하다/VV','되다/VV','있다/VV', '있다/VX','없다/VA','않다/VX','있다/VV','아니하다/VX'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNJbHEXAhfAT"
      },
      "source": [
        "# 불용어 제거\n",
        "df['tokens'] = df['tokens'].map(lambda x:[w for w in x if not w in set(stopwords)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1k3d6ohrSRj"
      },
      "source": [
        "# 유효한 1음절은 살리고 나머지는 제거\n",
        "hangul_1_except = regex.compile(r'^(?!일/NNG|돈/NNG|꿈/NNG|집/NNG)\\p{Hangul}{1}/\\w+$') # 파이프(|)로 구분해 입력. 맨마지막 단어에는 파이프 입력하지 말것."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioG0f40Ejtpd"
      },
      "source": [
        "df['tokens'] = df['tokens'].progress_map(lambda x:[w for w in x if not hangul_1_except.match(w)]) #매치되는 것을 제거한다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbnYMSuhkc6D"
      },
      "source": [
        "df['tokens']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUlpSmXqllBV"
      },
      "source": [
        "##### 동의어 처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa_2Kgi5loT8"
      },
      "source": [
        "# flashtext용 동의어 딕셔너리\n",
        "# 통일단어 : 바꿀단어\n",
        "#'startup':['start up','start ups','start-up','start-ups','start_up','start_ups'],\n",
        "\n",
        "synonym_dict = {\n",
        "'옥련':['옥련이'] # 부인?\n",
        "\n",
        "}\n",
        "kp.add_keywords_from_dict(synonym_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0IQcoarmPnT"
      },
      "source": [
        "# 동의어 처리 실행\n",
        "df['tokens'] = [[kp.replace_keywords(x) for x in w] for w in tqdm(df['tokens'])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YA5XDw6lpwH"
      },
      "source": [
        "##### 기타 전처리 (유효한 행만 남긱기)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzjLuAoNJPTt"
      },
      "source": [
        "# 특정 형태소가 들어간 행만 남기기\n",
        "query_list = ['울다/VV','훌쩍이다/VV'] # OR 조건\n",
        "# df['tokens'].map(lambda x:query in x)\n",
        "df[df['tokens'].map(lambda x:any(query in x for query in query_list))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VECFcpcpluLL"
      },
      "source": [
        "df['tokens'].map(lambda x:len(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQm-zeltrGKN"
      },
      "source": [
        "df['tokens'].map(lambda x:len(x)).describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgKbTW2Lt69h"
      },
      "source": [
        "df['tokens'].map(lambda x:len(x)).hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCsR9vChrHam"
      },
      "source": [
        "# token 개수가 N개 이상인 행만 살리기\n",
        "df = df[df['tokens'].map(lambda x:len(x)>=3)] #3개 이상\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImTloGfYrIvV"
      },
      "source": [
        "# paragraph 열 중복행이 있으면 제거 \n",
        "df = df.drop_duplicates(subset=['paragraph'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4dMziCs50Hq"
      },
      "source": [
        "# reset index\n",
        "df = df.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bqOMfrEVr-U"
      },
      "source": [
        "### 2. 키워드 추출 / 단어 네트워크"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neFgplf3l4Vf"
      },
      "source": [
        "# 각 작품별로 따로 분석하고 싶다면 아래 코드를 실행하고 분석 (# 제거하고 실행)\n",
        "# df = df[df['title']=='혈의 누/현대어 해석'] #혈의 누"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4b6HmBiV0va"
      },
      "source": [
        "##### Term Frequency (단순 빈도수)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6Ft6hoR62hN"
      },
      "source": [
        "tf_vectorizer = CountVectorizer(analyzer='word',\n",
        "                             lowercase=False,\n",
        "                             tokenizer=None,\n",
        "                             preprocessor=None,\n",
        "                             stop_words=['NNG'],\n",
        "                             token_pattern = r'(?u)\\b\\w\\w+(?:\\/)?\\w+\\b',\n",
        "                             min_df=50, # 최소 N개 문서(단락)에서 등장해야 함\n",
        "                             ngram_range=(1,2) #bigram까지\n",
        "                             )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdSTJS5G637a"
      },
      "source": [
        "tf_vector = tf_vectorizer.fit_transform(df['tokens'].astype(str))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u79xB8Ci666w"
      },
      "source": [
        "# 빈도수 내림차순으로 정렬\n",
        "tf_scores = tf_vector.toarray().sum(axis=0)\n",
        "tf_idx = np.argsort(-tf_scores)\n",
        "tf_scores = tf_scores[tf_idx]\n",
        "tf_vocab = np.array(tf_vectorizer.get_feature_names())[tf_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk0Flnxi67_N"
      },
      "source": [
        "# 상위 50개 단어\n",
        "print(list(zip(tf_vocab, tf_scores))[:50])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfHzwxcPVjkZ"
      },
      "source": [
        "# 워드 클라우드 (참고용)\n",
        "keywords = dict(zip(tf_vocab, tf_scores))\n",
        "\n",
        "# wordcloud = wordcloud.generate_from_text(texts)\n",
        "wordcloud = wordcloud.generate_from_frequencies(keywords)\n",
        "wordcloud = WordCloud(\n",
        "    font_path = font_path,\n",
        "    width = 800,\n",
        "    height = 800\n",
        ")\n",
        "wordcloud = wordcloud.generate_from_frequencies(keywords)\n",
        "array = wordcloud.to_array()\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "plt.imshow(array, interpolation=\"bilinear\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLH8kcR-69WJ"
      },
      "source": [
        "##### TF-IDF(빈도수 * 역문서 빈도수)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3-DDcVF7Au6"
      },
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(analyzer='word',\n",
        "                             lowercase=False,\n",
        "                             tokenizer=None,\n",
        "                             preprocessor=None,\n",
        "                             stop_words=['NNG'],\n",
        "                             token_pattern = r'(?u)\\b\\w\\w+(?:\\/)?\\w+\\b',\n",
        "                             min_df=50, \n",
        "                             ngram_range=(1,2), #bigram \n",
        "                             smooth_idf=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnA2emj17Ce8"
      },
      "source": [
        "tfidf_vector = tfidf_vectorizer.fit_transform(df['tokens'].astype(str))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me220sPY7EZ2"
      },
      "source": [
        "tfidf_scores = tfidf_vector.toarray().sum(axis=0)\n",
        "tfidf_idx = np.argsort(-tfidf_scores)\n",
        "tfidf_scores = tfidf_scores[tfidf_idx]\n",
        "tfidf_vocab = np.array(tfidf_vectorizer.get_feature_names())[tfidf_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvvOPuFk7Fh-"
      },
      "source": [
        "print(list(zip(tfidf_vocab, tfidf_scores))[:50]) #상위 50개 단어"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1ki6Zae7GNV"
      },
      "source": [
        "##### 단어 빈도수 테이블 정리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBq-Mu697IbE"
      },
      "source": [
        "###TF, TF-IDF 단어 테이블 정리###\n",
        "list(zip(tf_vocab, tf_scores,tfidf_vocab,tfidf_scores))[:100] #상위 100개\n",
        "tf_tfidf_vocab = pd.DataFrame(list(zip(tf_vocab, tf_scores,tfidf_vocab,tfidf_scores)),\n",
        "                              columns=['TF 단어','TF','TFIDF 단어','TFIDF'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl8fn1V-7KVa"
      },
      "source": [
        "tf_tfidf_vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFWwd--_7MV6"
      },
      "source": [
        "tf_tfidf_vocab.to_excel('이인직 키워드 빈도.xlsx') # 엑셀파일로 저장"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smiDeW6w7eqS"
      },
      "source": [
        "##### 코사인 유사도 기반의 단어-단어 행렬"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie4ukkrZ7i9R"
      },
      "source": [
        "tfidf_term_term_mat = cosine_similarity(tfidf_vector.T)\n",
        "tfidf_term_term_mat = pd.DataFrame(tfidf_term_term_mat,index=tfidf_vectorizer.vocabulary_,columns=tfidf_vectorizer.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUONw4eh7mNX"
      },
      "source": [
        "tfidf_term_term_mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2AnFfSc7ouu"
      },
      "source": [
        "# tf-idf 기준 상위 100개 단어만# tf-idf 기준 상위 100개 단어만\n",
        "tfidf_term_term_mat_100 = tfidf_term_term_mat[tfidf_term_term_mat.keys().isin(tfidf_vocab[:100])]\n",
        "tfidf_term_term_mat_100 = tfidf_term_term_mat_100[tfidf_term_term_mat_100.columns.intersection(tfidf_vocab[:100])]\n",
        "tfidf_term_term_mat_100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0ViqKGM9cpZ"
      },
      "source": [
        "# csv로 저장\n",
        "tfidf_term_term_mat_100.iloc[:100,:100].to_csv('단어 매트릭스.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vazfClXWke9K"
      },
      "source": [
        "## word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J3Rh5oW1PP4"
      },
      "source": [
        "### 모델링"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJUPiBUA0PGp"
      },
      "source": [
        "sentences = df['tokens'].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Di4JaVEkhSf"
      },
      "source": [
        "model = Word2Vec(sentences=sentences, vector_size=200, window=3, min_count=10) # min_count = 10이면 10회 이상 등장한 단어만 학습"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RlYfuhDl3Zu"
      },
      "source": [
        "# 유의어 뽑기\n",
        "model.wv.most_similar('소리/NNG', topn=20) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9Q519GH0pP_"
      },
      "source": [
        "# 유의어 뽑기\n",
        "model.wv.most_similar('울다/VV', topn=20) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFcTciRw1RK0"
      },
      "source": [
        "### 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZUqV0_n1Odq"
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import gensim \n",
        "import gensim.models as g\n",
        "\n",
        "# 그래프에서 마이너스 폰트 깨지는 문제에 대한 대처\n",
        "mpl.rcParams['axes.unicode_minus'] = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkxEgzza1Tq4"
      },
      "source": [
        "tsne =TSNE(n_components=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U373zbBK2y29"
      },
      "source": [
        "vocab = list(model.wv.key_to_index)\n",
        "X = model.wv[vocab]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVY8OIDA1Veg"
      },
      "source": [
        "X_tsne = tsne.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL-_FN4Y2EFK"
      },
      "source": [
        "%matplotlib inline  \n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "# 체크해보면 폰트 개수가 늘어났다\n",
        "sys_font=fm.findSystemFonts()\n",
        "print(f\"sys_font number: {len(sys_font)}\")\n",
        "\n",
        "nanum_font = [f for f in sys_font if 'Nanum' in f]\n",
        "print(f\"nanum_font number: {len(nanum_font)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl7dIaBN1kBS"
      },
      "source": [
        "# 100개의 단어에 대해서만 시각화\n",
        "X_tsne = tsne.fit_transform(X[:100,:])\n",
        "# X_tsne = tsne.fit_transform(X)\n",
        "\n",
        "w2v_df = pd.DataFrame(X_tsne, index=vocab[:100], columns=['x', 'y'])\n",
        "w2v_df.shape\n",
        "w2v_df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVx_f2nf2Kmk"
      },
      "source": [
        "# path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'  # 설치된 나눔글꼴중 원하는 녀석의 전체 경로를 가져오자\n",
        "# font_name = fm.FontProperties(fname=path, size=8).get_name()\n",
        "# print(font_name)\n",
        "# plt.rc('font', family=font_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBwAFNir3i8g"
      },
      "source": [
        "# !python --version\n",
        "# def current_font():\n",
        "#   print(f\"설정 폰트 글꼴: {plt.rcParams['font.family']}, 설정 폰트 사이즈: {plt.rcParams['font.size']}\")  # 파이썬 3.6 이상 사용가능하다\n",
        "        \n",
        "# current_font()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBNqRKKX2RxH"
      },
      "source": [
        "plt.rc('font', family='NanumBarunGothic')\n",
        "fig = plt.figure()\n",
        "fig.set_size_inches(40, 20)\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "ax.scatter(w2v_df['x'], w2v_df['y'])\n",
        "\n",
        "for word, pos in w2v_df.iterrows():\n",
        "    ax.annotate(word, pos, fontsize=20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}